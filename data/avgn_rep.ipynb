{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f04ecf9-5c64-489c-a000-dde6ddac0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import librosa\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sa\n",
    "import statsmodels.formula.api as sfa\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import SparseCoder\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "import pickle\n",
    "import parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16248b7c-687e-4c65-8056-cd9c1ad5e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "read_in = []\n",
    "for bird_num in ['b1053', 'B338']:\n",
    "    os.chdir( (f'/mnt/cube/Datasets/public_ds_starlings_ts_2019/{bird_num}/wavs').replace('.', 'p') )\n",
    "    for fileName in os.listdir(os.getcwd()):\n",
    "            if fileName.endswith('.wav'):\n",
    "                temp_wav, temp_sr = librosa.load(fileName)\n",
    "                read_in = np.append(read_in, temp_wav)\n",
    "train_spc = librosa.feature.melspectrogram(y = read_in, sr = temp_sr, n_fft = 2048, hop_length = 512, win_length = 1024)\n",
    "train_spc_db = librosa.power_to_db(train_spc, ref = np.max, top_db = 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c2fd7-7787-4165-b144-757caddc67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_learner = DictionaryLearning(n_components = 15, alpha = 0.1, max_iter = 1000, tol = 1e-3)\n",
    "\n",
    "train_transform = dict_learner.fit_transform(train_spc_db.T)\n",
    "coder = SparseCoder(dictionary = dict_learner.components_, transform_algorithm = 'lasso_lars', transform_alpha = 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0d50d-bc3b-4d25-9396-5ca7c43f6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xcomp = coder.transform( train_spc_db.T )\n",
    "# hist_quant = []\n",
    "# for i in range(0, Xcomp.shape[1]):\n",
    "#     hist_quant.append(np.quantile(Xcomp[:,i], (0.01, 0.99)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4709e565-3953-4103-9801-6c918d87516a",
   "metadata": {},
   "source": [
    "## General use, label data for each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f439c-8f51-4aaa-818d-bf9a5769c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import avgn.utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672185e-1948-41af-943a-309e1912d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create a name for our dataset\n",
    "DATASET_ID = 'koumura_bengalese_finch'\n",
    "\n",
    "# create a unique datetime identifier for the files output by this notebook\n",
    "DT_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# grab a list of all the raw waveforms\n",
    "wav_list = list(RAW_DATASET_LOC.glob('Bird*/Wave/*.wav'))\n",
    "len(wav_list), np.sort(wav_list)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7cd00d-6c54-45c6-9ff8-a3a41f640973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a list of all of the raw annotation files for each bird\n",
    "annotation_files = list(RAW_DATASET_LOC.glob('Bird*/Annotation.xml'))\n",
    "len(annotation_files), np.sort(annotation_files)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d2f68-b441-495d-8bc2-201424b13c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree\n",
    "import xml.dom.minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69229511-2f76-4b21-a632-2b02eaf2fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a sample of the XML\n",
    "parssed  = xml.dom.minidom.parse(annotation_files[0].as_posix()) \n",
    "pretty_xml_as_string = dom.toprettyxml()\n",
    "# print(pretty_xml_as_string[:400] + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e313e0-337c-401d-86b6-bfabe992fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"bird\",\n",
    "            \"WaveFileName\",\n",
    "            \"Position\",\n",
    "            \"Length\",\n",
    "            \"NumNote\",\n",
    "            \"NotePositions\",\n",
    "            \"NoteLengths\",\n",
    "            \"NoteLabels\",\n",
    "        ]\n",
    "    )\n",
    "song_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3efbcb-76b7-4967-929c-e8b83569a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through XML annotation files\n",
    "for bird_loc in tqdm(annotation_files):\n",
    "    # grab the\n",
    "    bird_xml = xml.etree.ElementTree.parse(bird_loc).getroot()\n",
    "    bird = bird_loc.parent.stem\n",
    "    # loop through each \"sequence\" in the datset (corresponding to a bout)\n",
    "    for element in tqdm(bird_xml.getchildren(), leave=False):\n",
    "        if element.tag == \"Sequence\":\n",
    "            notePositions = []\n",
    "            noteLengths = []\n",
    "            noteLabels = []\n",
    "            # get the metadata for that sequence \n",
    "            for seq_element in element.getchildren():\n",
    "                if seq_element.tag == \"Position\":\n",
    "                    position = seq_element.text\n",
    "                elif seq_element.tag == \"Length\":\n",
    "                    length = seq_element.text\n",
    "                elif seq_element.tag == \"WaveFileName\":\n",
    "                    WaveFileName = seq_element.text\n",
    "                elif seq_element.tag == \"NumNote\":\n",
    "                    NumNote = seq_element.text\n",
    "                # get the metadata for the note\n",
    "                elif seq_element.tag == \"Note\":\n",
    "                    for note_element in seq_element.getchildren():\n",
    "                        if note_element.tag == \"Label\":\n",
    "                            noteLabels.append(note_element.text)\n",
    "                        elif note_element.tag == \"Position\":\n",
    "                            notePositions.append(note_element.text)\n",
    "                        elif note_element.tag == \"Length\":\n",
    "                            noteLengths.append(note_element.text)\n",
    "            # add to the pandas dataframe\n",
    "            song_df.loc[len(song_df)] = [\n",
    "                bird,\n",
    "                WaveFileName,\n",
    "                position,\n",
    "                length,\n",
    "                NumNote,\n",
    "                notePositions,\n",
    "                noteLengths,\n",
    "                noteLabels,\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412f740-0efe-4274-b650-151b5969e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avgn.utils.audio import get_samplerate\n",
    "import librosa\n",
    "from avgn.utils.json import NoIndent, NoIndentEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7949bd8-dc2d-4063-9323-b7d0dfa5bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each bird\n",
    "for bird in tqdm(np.unique(song_df.bird)):\n",
    "    # grab that bird's annotations\n",
    "    bird_df = song_df[song_df.bird == bird]\n",
    "    \n",
    "    # for each wav file produced by that bird\n",
    "    for wfn in tqdm(bird_df.WaveFileName.unique(), leave=False):\n",
    "        \n",
    "        wfn_df = bird_df[bird_df.WaveFileName == wfn]\n",
    "        \n",
    "        # get the location of the wav\n",
    "        wav_loc = RAW_DATASET_LOC / bird / \"Wave\" / wfn\n",
    "    \n",
    "        # get the wav samplerate and duration\n",
    "        sr = get_samplerate(wav_loc.as_posix())\n",
    "        wav_duration = librosa.get_duration(filename=wav_loc)\n",
    "        \n",
    "        # make json dictionary\n",
    "        json_dict = {}\n",
    "        # add species\n",
    "        json_dict[\"species\"] = \"Lonchura striata domestica\"\n",
    "        json_dict[\"common_name\"] = \"Bengalese finch\"\n",
    "        json_dict[\"wav_loc\"] = wav_loc.as_posix()\n",
    "        # rate and length\n",
    "        json_dict[\"samplerate_hz\"] = sr\n",
    "        json_dict[\"length_s\"] = wav_duration\n",
    "        \n",
    "        # make a dataframe of wav info\n",
    "        seq_df = pd.DataFrame(\n",
    "            (\n",
    "                [\n",
    "                    [\n",
    "                        list(np.repeat(sequence_num, len(row.NotePositions))),\n",
    "                        list(row.NoteLabels),\n",
    "                        np.array(\n",
    "                            (np.array(row.NotePositions).astype(\"int\") + int(row.Position))\n",
    "                            / sr\n",
    "                        ).astype(\"float64\"),\n",
    "                        np.array(\n",
    "                            (\n",
    "                                np.array(row.NotePositions).astype(\"int\")\n",
    "                                + np.array(row.NoteLengths).astype(\"int\")\n",
    "                                + int(row.Position)\n",
    "                            )\n",
    "                            / sr\n",
    "                        ).astype(\"float64\"),\n",
    "                    ]\n",
    "                    for sequence_num, (idx, row) in enumerate(wfn_df.iterrows())\n",
    "                ]\n",
    "            ),\n",
    "            columns=[\"sequence_num\", \"labels\", \"start_times\", \"end_times\"],\n",
    "        )\n",
    "        \n",
    "        # add syllable information\n",
    "        json_dict[\"indvs\"] = {\n",
    "            bird: {\n",
    "                \"notes\": {\n",
    "                    \"start_times\": NoIndent(\n",
    "                        list(np.concatenate(seq_df.start_times.values))\n",
    "                    ),\n",
    "                    \"end_times\": NoIndent(list(np.concatenate(seq_df.end_times.values))),\n",
    "                    \"labels\": NoIndent(list(np.concatenate(seq_df.labels.values))),\n",
    "                    \"sequence_num\": NoIndent(\n",
    "                        [int(i) for i in np.concatenate(seq_df.sequence_num.values)]\n",
    "                    ),\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        \n",
    "        # dump dict into json format\n",
    "        json_txt = json.dumps(json_dict, cls=NoIndentEncoder, indent=2)\n",
    "\n",
    "        wav_stem = bird + \"_\" + wfn.split(\".\")[0]\n",
    "        json_out = (\n",
    "            DATA_DIR / \"processed\" / DATASET_ID / DT_ID / \"JSON\" / (wav_stem + \".JSON\")\n",
    "        )\n",
    "\n",
    "        # save json\n",
    "        avgn.utils.paths.ensure_dir(json_out.as_posix())\n",
    "        print(json_txt, file=open(json_out.as_posix(), \"w\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358a70d-9f8b-4adb-843f-3b49cd406574",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a4726-5d8e-4189-87df-6f4ce65bf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/mnt/cube/ntansey/vocalization_segmentation/')\n",
    "from vocalseg.utils import butter_bandpass_filter, spectrogram, int16tofloat32, plot_spec\n",
    "from vocalseg.continuity_filtering import continuity_segmentation\n",
    "from vocalseg.continuity_filtering import plot_labelled_elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3676f34-0c54-4b2a-8b7c-ac574e586e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 versions of data\n",
    "b1, srb1 = librosa.load('example_birdsong.wav')\n",
    "\n",
    "mel_spc = librosa.feature.melspectrogram(y = temp_song, sr = temp_rate, n_fft = 2048, hop_length = 512, win_length = 1024)\n",
    "\n",
    "b1_spec = librosa.power_to_db(mel_spc, ref = np.max)\n",
    "b1_sparse = coder.transform(b1_spec.T)  # \n",
    "b1_srecon = Xb1 @ coder.dictionary   # reconstructed from sparse elements back to mel spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ab220-9239-4449-8f89-007dfde6587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### segmentation parameters\n",
    "n_fft=1024\n",
    "hop_length_ms=2\n",
    "win_length_ms=4\n",
    "ref_level_db=20\n",
    "pre=0.97\n",
    "min_level_db=-60\n",
    "min_level_db_floor = -20\n",
    "db_delta = 5\n",
    "silence_threshold = 0.05\n",
    "min_silence_for_spec=0.5\n",
    "max_vocal_for_spec=0.5,\n",
    "min_syllable_length_s = 0.01\n",
    "butter_min = 500\n",
    "butter_max = 15000\n",
    "spectral_range = [500, 15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c077dbb-857d-4e5c-9260-3d647e427b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments on each song from waveform, keep differences of clusterability from being related to segmenting\n",
    "\n",
    "# results = dynamic_threshold_segmentation(\n",
    "#     b1,\n",
    "#     srb1,\n",
    "#     n_fft=n_fft,\n",
    "#     hop_length_ms=hop_length_ms,\n",
    "#     win_length_ms=win_length_ms,\n",
    "#     ref_level_db=ref_level_db,\n",
    "#     pre=pre,\n",
    "#     min_level_db=min_level_db,\n",
    "#     silence_threshold = silence_threshold,\n",
    "#     verbose=True,\n",
    "#     min_syllable_length_s = 0.2\n",
    "# )\n",
    "\n",
    "# segment\n",
    "results = dynamic_threshold_segmentation(\n",
    "    data,\n",
    "    rate,\n",
    "    n_fft=n_fft,\n",
    "    hop_length_ms=hop_length_ms,\n",
    "    win_length_ms=win_length_ms,\n",
    "    min_level_db_floor=min_level_db_floor,\n",
    "    db_delta=db_delta,\n",
    "    ref_level_db=ref_level_db,\n",
    "    pre=pre,\n",
    "    min_silence_for_spec=min_silence_for_spec,\n",
    "    max_vocal_for_spec=max_vocal_for_spec,\n",
    "    min_level_db=min_level_db,\n",
    "    silence_threshold=silence_threshold,\n",
    "    verbose=True,\n",
    "    min_syllable_length_s=min_syllable_length_s,\n",
    "    spectral_range=spectral_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39413b3-4846-4ec5-a2e8-0a8cb34ac9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
