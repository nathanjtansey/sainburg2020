{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we segment the waveform into putative syllables\n",
    "When a dataset is not pre-segmented into individiual vocal units, we can try to segment it computationally. Here we'll use dynamic thresholding segmentation to segment bouts into syllables.\n",
    "\n",
    "This works very well with low-noise datasets with clearly defined syllables like Bengalese finch song. You might need to rely on other methods for noisier data. \n",
    "\n",
    "You can also try denoising your data first, e.g. with [noisereduce](https://github.com/timsainb/noisereduce) to get better results.\n",
    "\n",
    "You'll need to install the [vocalseg](https://github.com/timsainb/vocalization-segmentation) package to use this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:05:13.078105Z",
     "start_time": "2020-11-19T21:05:10.949736Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/ntansey/avgn_test/avgn_paper/avgn/utils/general.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2024-11-19 16:57:10.941471: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732064230.967152  865169 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732064230.975021  865169 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from avgn.utils.hparams import HParams\n",
    "from avgn.dataset import DataSet\n",
    "import tensorflow\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:05:13.082298Z",
     "start_time": "2020-11-19T21:05:13.079995Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'koumura_bengalese_finch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:05:13.093109Z",
     "start_time": "2020-11-19T21:05:13.084185Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a set of hyperparameters for processing this dataset.  \n",
    "hparams = HParams(\n",
    "    num_mel_bins = 64,\n",
    "    mel_lower_edge_hertz=500,\n",
    "    mel_upper_edge_hertz=15000,\n",
    "    butter_lowcut = 500,\n",
    "    butter_highcut = 15000,\n",
    "    ref_level_db = 20,\n",
    "    min_level_db = -30,\n",
    "    mask_spec = True,\n",
    "    win_length_ms = 10,\n",
    "    hop_length_ms = 2,\n",
    "    nex=-1,\n",
    "    n_jobs=-1,\n",
    "    verbosity = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset object\n",
    "The dataset object loads JSONs corresponding to `DATASET_ID` in the data folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:05:24.116602Z",
     "start_time": "2020-11-19T21:05:13.094637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7665c333d14f738629940e13bc5db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading json:   0%|          | 0/2964 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 654 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2480 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2964 out of 2964 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66aba5a2db214f3f9a34c4d326809953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "getting unique individuals:   0%|          | 0/2964 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 16:57:23.501051: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-19 16:57:23.501137: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:137] retrieving CUDA diagnostic information for host: txori.ucsd.edu\n",
      "2024-11-19 16:57:23.501148: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:144] hostname: txori.ucsd.edu\n",
      "2024-11-19 16:57:23.501281: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:168] libcuda reported version is: 520.61.5\n",
      "2024-11-19 16:57:23.501317: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:172] kernel reported version is: 520.61.5\n",
      "2024-11-19 16:57:23.501327: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:259] kernel version seems to match DSO: 520.61.5\n"
     ]
    }
   ],
   "source": [
    "# create a dataset object, which\n",
    "dataset = DataSet(DATASET_ID, hparams = hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:05:24.127276Z",
     "start_time": "2020-11-19T21:05:24.118720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"species\": \"Lonchura striata domestica\",\n",
      "    \"common_name\": \"Bengalese finch\",\n",
      "    \"wav_loc\": \"/mnt/cube/ntansey/avgn_test/avgn_paper/data/raw/koumura/zip_contents/Bird4/Wave/221.wav\",\n",
      "    \"samplerate_hz\": 32000,\n",
      "    \"length_s\": 12.592,\n",
      "    \"indvs\": {\n",
      "        \"Bird4\": {\n",
      "            \"notes\": {\n",
      "                \"start_times\": [\n",
      "                    1.158,\n",
      "                    1.317,\n",
      "             ...\n"
     ]
    }
   ],
   "source": [
    "# to make sure everything loaded correctly, lets look at a sample JSON\n",
    "print(json.dumps(dataset.sample_json, indent=4, default=str)[:400] + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:05:24.143852Z",
     "start_time": "2020-11-19T21:05:24.128976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2964"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many wavs are in the dataset?\n",
    "len(dataset.data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:06:36.070294Z",
     "start_time": "2020-11-19T21:06:36.066541Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:07:15.896664Z",
     "start_time": "2020-11-19T21:07:15.890734Z"
    }
   },
   "outputs": [],
   "source": [
    "### segmentation parameters\n",
    "n_fft=1024\n",
    "hop_length_ms=2\n",
    "win_length_ms=4\n",
    "ref_level_db=20\n",
    "pre=0.97\n",
    "min_level_db=-60\n",
    "min_level_db_floor = -20\n",
    "db_delta = 5\n",
    "silence_threshold = 0.05\n",
    "min_silence_for_spec=0.5\n",
    "max_vocal_for_spec=0.5,\n",
    "min_syllable_length_s = 0.01\n",
    "butter_min = 500\n",
    "butter_max = 15000\n",
    "spectral_range = [500, 15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m os\u001b[38;5;241m.\u001b[39mgetcwd()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()\n",
    "# current = os.getcwd()\n",
    "\n",
    "# os.chdir('/mnt/cube/ntansey/vocalization_segmentation/')\n",
    "\n",
    "# os.chdir(current)\n",
    "# # # os.chdir('/mnt/cube/ntansey/vocalization_segmentation/')\n",
    "# # from vocalization_segmentation.vocalseg.utils import butter_bandpass_filter, spectrogram, int16tofloat32, plot_spec\n",
    "# # from vocalseg.continuity_filtering import continuity_segmentation\n",
    "# # from vocalseg.continuity_filtering import plot_labelled_elements\n",
    "\n",
    "# from ..vocalization_segmentation.vocalseg.utils import butter_bandpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First lets try segmenting an example to make sure the segmentation looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:09:11.959092Z",
     "start_time": "2020-11-19T21:09:11.954728Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.utils.audio import load_wav, read_wav\n",
    "\n",
    "# os.getcwd()\n",
    "# current = os.getcwd()\n",
    "\n",
    "# os.chdir('/mnt/cube/ntansey/vocalization_segmentation/')\n",
    "\n",
    "from vocalseg.dynamic_thresholding import dynamic_threshold_segmentation\n",
    "from vocalseg.dynamic_thresholding import plot_segmented_spec, plot_segmentations\n",
    "import matplotlib.pyplot as plt\n",
    "import vocalseg\n",
    "\n",
    "# os.chdir(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:08:26.949855Z",
     "start_time": "2020-11-19T21:08:26.943451Z"
    }
   },
   "outputs": [],
   "source": [
    "rate, data = load_wav(dataset.data_files['Bird8_108'].data[\"wav_loc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:08:37.432210Z",
     "start_time": "2020-11-19T21:08:37.247405Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest silence 1.0999999999999996\n",
      "longest vocalization 0.1039999999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# segment\n",
    "results = dynamic_threshold_segmentation(\n",
    "    data,\n",
    "    rate,\n",
    "    n_fft=n_fft,\n",
    "    hop_length_ms=hop_length_ms,\n",
    "    win_length_ms=win_length_ms,\n",
    "    min_level_db_floor=min_level_db_floor,\n",
    "    db_delta=db_delta,\n",
    "    ref_level_db=ref_level_db,\n",
    "    pre=pre,\n",
    "    min_silence_for_spec=min_silence_for_spec,\n",
    "    max_vocal_for_spec=max_vocal_for_spec,\n",
    "    min_level_db=min_level_db,\n",
    "    silence_threshold=silence_threshold,\n",
    "    verbose=True,\n",
    "    min_syllable_length_s=min_syllable_length_s,\n",
    "    spectral_range=spectral_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:09:38.602387Z",
     "start_time": "2020-11-19T21:09:38.315660Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_segmentations(\n",
    "    results[\"spec\"],\n",
    "    results[\"vocal_envelope\"],\n",
    "    results[\"onsets\"],\n",
    "    results[\"offsets\"],\n",
    "    hop_length_ms,\n",
    "    rate,\n",
    "    figsize=(20,5)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment the full dataset \n",
    "- for each json, load the wav file - segment the file into start and end times\n",
    "- plot the segmentation\n",
    "- add to the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:13:20.858167Z",
     "start_time": "2020-11-19T21:13:20.853947Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.utils.json import NoIndent, NoIndentEncoder\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:13:38.977861Z",
     "start_time": "2020-11-19T21:13:38.974037Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.signalprocessing.filtering import butter_bandpass_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:13:55.599803Z",
     "start_time": "2020-11-19T21:13:55.595610Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.utils.paths import DATA_DIR, most_recent_subdirectory, ensure_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:11:14.568419Z",
     "start_time": "2020-11-19T21:11:14.564425Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message = \"'tqdm_notebook' object has no attribute 'sp'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:11:20.668225Z",
     "start_time": "2020-11-19T21:11:20.652863Z"
    }
   },
   "outputs": [],
   "source": [
    "def segment_spec_custom(key, df, save=False, plot=False):\n",
    "    # load wav\n",
    "    rate, data = load_wav(df.data[\"wav_loc\"])\n",
    "    # filter data\n",
    "    data = butter_bandpass_filter(data, butter_min, butter_max, rate)\n",
    "\n",
    "    # segment\n",
    "    results = dynamic_threshold_segmentation(\n",
    "        data,\n",
    "        rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length_ms=hop_length_ms,\n",
    "        win_length_ms=win_length_ms,\n",
    "        min_level_db_floor=min_level_db_floor,\n",
    "        db_delta=db_delta,\n",
    "        ref_level_db=ref_level_db,\n",
    "        pre=pre,\n",
    "        min_silence_for_spec=min_silence_for_spec,\n",
    "        max_vocal_for_spec=max_vocal_for_spec,\n",
    "        min_level_db=min_level_db,\n",
    "        silence_threshold=silence_threshold,\n",
    "        verbose=True,\n",
    "        min_syllable_length_s=min_syllable_length_s,\n",
    "        spectral_range=spectral_range,\n",
    "    )\n",
    "    if results is None:\n",
    "        return\n",
    "    if plot:\n",
    "        plot_segmentations(\n",
    "            results[\"spec\"],\n",
    "            results[\"vocal_envelope\"],\n",
    "            results[\"onsets\"],\n",
    "            results[\"offsets\"],\n",
    "            hop_length_ms,\n",
    "            rate,\n",
    "            figsize=(100, 5),\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    # save the results\n",
    "    json_out = (\n",
    "        DATA_DIR\n",
    "        / \"processed\"\n",
    "        / (DATASET_ID + \"_segmented\")\n",
    "        / DT_ID\n",
    "        / \"JSON\"\n",
    "        / (key + \".JSON\")\n",
    "    )\n",
    "\n",
    "    json_dict = df.data.copy()\n",
    "\n",
    "    json_dict[\"indvs\"][list(df.data[\"indvs\"].keys())[0]][\"syllables\"] = {\n",
    "        \"start_times\": NoIndent(list(results[\"onsets\"])),\n",
    "        \"end_times\": NoIndent(list(results[\"offsets\"])),\n",
    "    }\n",
    "\n",
    "    json_txt = json.dumps(json_dict, cls=NoIndentEncoder, indent=2)\n",
    "    # save json\n",
    "    if save:\n",
    "        ensure_dir(json_out.as_posix())\n",
    "        print(json_txt, file=open(json_out.as_posix(), \"w\"))\n",
    "\n",
    "    print(json_txt)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:11:33.171094Z",
     "start_time": "2020-11-19T21:11:33.157100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bird0', 'Bird1', 'Bird10', 'Bird2', 'Bird3', 'Bird4', 'Bird5',\n",
       "       'Bird6', 'Bird7', 'Bird8', 'Bird9'], dtype='<U6')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indvs = np.array(['_'.join(list(i)) for i in dataset.json_indv])\n",
    "np.unique(indvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:14:20.057673Z",
     "start_time": "2020-11-19T21:14:20.054407Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:14:20.201302Z",
     "start_time": "2020-11-19T21:14:20.196566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-11-19_16-57-41'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a unique datetime identifier for the files output by this notebook\n",
    "DT_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "DT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T21:14:53.841017Z",
     "start_time": "2020-11-19T21:14:20.328747Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nex = 3\n",
    "for indv in tqdm(np.unique(indvs), desc=\"individuals\"):\n",
    "    print(indv)\n",
    "    indv_keys = np.array(list(dataset.data_files.keys()))[indvs == indv][:nex]\n",
    "\n",
    "    joblib.Parallel(n_jobs=1, verbose=11)(\n",
    "            joblib.delayed(segment_spec_custom)(key, dataset.data_files[key], plot=True) \n",
    "                 for key in tqdm(indv_keys, desc=\"files\", leave=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate segmentations for the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T23:07:08.642098Z",
     "start_time": "2020-11-19T23:05:03.991410Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# os.getcwd()\n",
    "# current = os.getcwd()\n",
    "\n",
    "# os.chdir('/mnt/cube/ntansey/vocalization_segmentation/')\n",
    "\n",
    "\n",
    "nex = -1\n",
    "for indv in tqdm(np.unique(indvs), desc=\"individuals\"):\n",
    "    print(indv)\n",
    "    indv_keys = np.array(list(dataset.data_files.keys()))[indvs == indv]\n",
    "\n",
    "    joblib.Parallel(n_jobs=-1, verbose=11)(\n",
    "            joblib.delayed(segment_spec_custom)(key, dataset.data_files[key], save=True) \n",
    "                 for key in tqdm(indv_keys, desc=\"files\", leave=False)\n",
    "        )\n",
    "\n",
    "\n",
    "# os.chdir(current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
